{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xcs229ii_sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "140bbf434af94ddebbbf1e48b4e58c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84e5b335e2454e82a90574ebbf14961c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e678d909e3742aa86bcb9d03e3043ae",
              "IPY_MODEL_317f63a8df674833abdb7c3c2bf4144b",
              "IPY_MODEL_c1af83ecdd0042edae8781e6f2f456a0"
            ]
          }
        },
        "84e5b335e2454e82a90574ebbf14961c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e678d909e3742aa86bcb9d03e3043ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27d0c52b4da2404893fd377a01bc956c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e073ee1534943e786ee529318a99508"
          }
        },
        "317f63a8df674833abdb7c3c2bf4144b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e799e0579314424ea3f74f9784e23bfa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf1dd36e2c2140b2a5e3d28b64de782c"
          }
        },
        "c1af83ecdd0042edae8781e6f2f456a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_132ee7d8c94d40d0bc3760a116b7bce8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:09&lt;00:00, 30307831.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01895a4c4fc34413a1008a1d5e4925ff"
          }
        },
        "27d0c52b4da2404893fd377a01bc956c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e073ee1534943e786ee529318a99508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e799e0579314424ea3f74f9784e23bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf1dd36e2c2140b2a5e3d28b64de782c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "132ee7d8c94d40d0bc3760a116b7bce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01895a4c4fc34413a1008a1d5e4925ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammarhusain/XCS229ii-project/blob/main/xcs229ii_sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD_64TSfk_2N"
      },
      "source": [
        "## Ammar's XCS229ii experiments\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG86J6b8rzVA",
        "outputId": "f45ed346-6044-4b96-e831-0d9551f0ecc7"
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "# !pip uninstall -y stable-baselines3[mpi]\n",
        "# !pip install stable-baselines3[mpi]==2.10.0\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3.git\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# function to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3.git\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3.git to /tmp/pip-req-build-beqyvplz\n",
            "  Running command git clone -q https://github.com/DLR-RM/stable-baselines3.git /tmp/pip-req-build-beqyvplz\n",
            "Requirement already satisfied: gym<0.20,>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a6) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a6) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a6) (1.10.0+cu111)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a6) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a6) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a6) (3.2.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3==1.3.1a6) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3==1.3.1a6) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.20,>=0.17->stable-baselines3==1.3.1a6) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->stable-baselines3==1.3.1a6) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a6) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a6) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3==1.3.1a6) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3==1.3.1a6) (2018.9)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-1.3.1a6-py3-none-any.whl size=164637 sha256=452a84d7e4738f1d411b6fcc7031650fbbc33eb9abf882a502d3c353b777a623\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h_d8n8mp/wheels/63/fa/0a/d71d604917fd5c427dffe42a64e4d3071d4b79d57ac2fb5a8b\n",
            "Successfully built stable-baselines3\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-1.3.1a6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jpKTy5HU979",
        "outputId": "df5982e0-c1bb-40f9-cb00-1fa4f36981e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "140bbf434af94ddebbbf1e48b4e58c78",
            "84e5b335e2454e82a90574ebbf14961c",
            "4e678d909e3742aa86bcb9d03e3043ae",
            "317f63a8df674833abdb7c3c2bf4144b",
            "c1af83ecdd0042edae8781e6f2f456a0",
            "27d0c52b4da2404893fd377a01bc956c",
            "8e073ee1534943e786ee529318a99508",
            "e799e0579314424ea3f74f9784e23bfa",
            "bf1dd36e2c2140b2a5e3d28b64de782c",
            "132ee7d8c94d40d0bc3760a116b7bce8",
            "01895a4c4fc34413a1008a1d5e4925ff"
          ]
        },
        "id": "glN6gy1gk_2N",
        "outputId": "db0a22da-dff0-416c-a84a-2d8736c97b10"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# separate out some training data to train the RL agent\n",
        "half_data_size = int(len(trainset)/2)\n",
        "\n",
        "rl_agent_trainset = torch.utils.data.Subset(trainset, range(0,int(0.8*half_data_size)))\n",
        "rl_agent_testset = torch.utils.data.Subset(trainset, range(int(0.8*half_data_size), half_data_size))\n",
        "\n",
        "hyp_opt_trainset = torch.utils.data.Subset(trainset, range(0,int(0.8*len(trainset))))\n",
        "hyp_opt_testset = torch.utils.data.Subset(trainset, range(int(0.8*len(trainset)), len(trainset)))\n",
        "\n",
        "print(f\"Full dataset size:  train={len(trainset)} test={len(testset)}\")\n",
        "print(f\"Use a subset of the training data to train the Hyp-RL agent : train={len(rl_agent_trainset)} val={len(rl_agent_testset)}\")\n",
        "\n",
        "print(f\"Use a subset of the training data to compare RL agent against HypOpt baseline  : train={len(hyp_opt_trainset)} val={len(hyp_opt_testset)}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140bbf434af94ddebbbf1e48b4e58c78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Full dataset size:  train=50000 test=10000\n",
            "Use a subset of the training data to train the Hyp-RL agent : train=20000 val=5000\n",
            "Use a subset of the training data to compare RL agent against HypOpt baseline  : train=40000 val=10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGn-0O64lHqh"
      },
      "source": [
        "## function to train and evaluate the model given the hyperparameter setting\n",
        "\n",
        "## define the neural network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def evaluateFullDataset(hp_learning_rate=0.001):\n",
        "  full_train = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "  full_test = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "  net = Net()\n",
        "  loss_criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=hp_learning_rate, momentum=0.9)\n",
        "  trainAndEvaluateModel(net, loss_criterion, optimizerm, rl_agent_train, rl_agent_test)\n",
        "\n",
        "def trainAndEvaluateModel(net, loss_criterion, optimizer, train, test):\n",
        "  ## Train the model\n",
        "  for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(train, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs)\n",
        "          loss = loss_criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "              # print('[%d, %5d] loss: %.3f' %\n",
        "              #       (epoch + 1, i + 1, running_loss / 2000))\n",
        "              running_loss = 0.0\n",
        "  #print('Finished Training')\n",
        "\n",
        "  ## Test the model\n",
        "\n",
        "  # # print images\n",
        "  # dataiter = iter(test)\n",
        "  # images, labels = dataiter.next()\n",
        "  # imshow(torchvision.utils.make_grid(images))\n",
        "  # print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "  # outputs = net(images)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in test:\n",
        "          images, labels = data\n",
        "          # calculate outputs by running images through the network \n",
        "          outputs = net(images)\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f\"Accuracy of the network on the {len(test)} test images: {(100 * correct / total)}%\")\n",
        "  return (100 * correct / total)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALe425tvo_mb"
      },
      "source": [
        "## Build the RL environment and agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t4pXmwpo-tG"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "import copy\n",
        "\n",
        "   \n",
        "class TunableHP:\n",
        "  def __init__(self, train_set, eval_set):\n",
        "    self.hyperparameters = {\"learning_rate\":[0.0001, 0.001, 0.01, 0.1, 1.0],\n",
        "                            \"batch_size\": [2,4, 6,8]}\n",
        "\n",
        "    #self.hyperparameters = {\"learning_rate\":[-5,-4,-3,-2,-1,0,-1,-2,-3,-4,-5]}\n",
        "    self.hyperparameter_keys = list(self.hyperparameters)\n",
        "\n",
        "    self.train_set = train_set\n",
        "    self.eval_set = eval_set\n",
        "\n",
        "  def mapStateToHP(self,state):\n",
        "    hp_dict = {}\n",
        "    for p,i in enumerate(state):\n",
        "      param_key = self.hyperparameter_keys[p]\n",
        "      hp_dict[param_key] = self.hyperparameters[param_key][i]\n",
        "    return hp_dict\n",
        "  \n",
        "  def getGridSize(self):\n",
        "    return [len(self.hyperparameters[k]) for k in self.hyperparameter_keys]\n",
        "\n",
        "  def evaluateRLAgent(self, hp_dict):\n",
        "    print(f\"Running evaluation for : {hp_dict}\")\n",
        "    rl_agent_train = torch.utils.data.DataLoader(self.train_set, batch_size=hp_dict['batch_size'],\n",
        "                                            shuffle=True, num_workers=2)\n",
        "    rl_agent_test = torch.utils.data.DataLoader(self.eval_set, batch_size=hp_dict['batch_size'],\n",
        "                                          shuffle=False, num_workers=2)\n",
        "    net = Net()\n",
        "    loss_criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=hp_dict['learning_rate'], momentum=0.9)\n",
        "    return trainAndEvaluateModel(net, loss_criterion, optimizer, rl_agent_train, rl_agent_test)\n",
        "\n",
        "class HypRLGridEnv(gym.Env):\n",
        "  \"\"\"\n",
        "  Custom Environment that follows gym interface.\n",
        "  This is a simple env where the agent must learn to go always left. \n",
        "  \"\"\"\n",
        "  # Because of google colab, we cannot implement the GUI ('human' render mode)\n",
        "  metadata = {'render.modes': ['console']}\n",
        "  MAX_ITER = 10\n",
        "\n",
        "  def __init__(self, tunableParams=TunableHP(rl_agent_trainset, rl_agent_testset)):\n",
        "    super(HypRLGridEnv, self).__init__()\n",
        "\n",
        "    self.tunableParams = tunableParams\n",
        "\n",
        "    # Size of the grid\n",
        "    self.grid_size = tunableParams.getGridSize()\n",
        "    \n",
        "    # Define action and observation space\n",
        "    # They must be gym.spaces objects\n",
        "    # Example when using discrete actions, we have two: left and right\n",
        "    n_actions = 3\n",
        "    self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.grid_size),), dtype=np.int32)\n",
        "    # The observation will be the coordinate of the agent\n",
        "    # this can be described both by Discrete and Box space\n",
        "    self.observation_space = spaces.MultiDiscrete(self.grid_size)\n",
        "    self.eval_cache = np.zeros(self.grid_size)\n",
        "\n",
        "  def eval(self, state):\n",
        "    state = tuple(state)\n",
        "    if self.eval_cache[state] == [0.0]:\n",
        "      # train & test the model for these hyperparameters\n",
        "      self.eval_cache[state] = self.tunableParams.evaluateRLAgent(self.tunableParams.mapStateToHP(state))\n",
        "    return self.eval_cache[state]\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Important: the observation must be a numpy array\n",
        "    :return: (np.array) \n",
        "    \"\"\"\n",
        "    # reset the number of iterations for this agent\n",
        "    self.iter = 0\n",
        "    # Initialize the agent at the right of the grid\n",
        "    self.agent_state = np.random.randint(self.grid_size)\n",
        "    self.reward = self.eval(self.agent_state)\n",
        "    self.best = {'state':copy.deepcopy(self.agent_state), 'val':self.eval(self.agent_state)}\n",
        "    self.visited = {}\n",
        "    self.visited[tuple(self.agent_state)] = True\n",
        "    return np.array(self.agent_state) \n",
        "\n",
        "  def step(self, action):\n",
        "    self.iter += 1\n",
        "\n",
        "    for i, _ in enumerate(action):\n",
        "      self.agent_state[i] += action[i]\n",
        "      # Account for the boundaries of the grid\n",
        "      self.agent_state[i] = np.clip(self.agent_state[i], 0, self.grid_size[i]-1)\n",
        "\n",
        "    # We are done when we visit the same state twice or have taken more iterations than MAX\n",
        "    done = bool(self.iter >= self.MAX_ITER or tuple(self.agent_state) in self.visited)\n",
        "\n",
        "    self.visited[tuple(self.agent_state)] = True\n",
        "\n",
        "    # reward idea #1\n",
        "    # Reward is minimum of whatever val loss we saw so far\n",
        "    self.reward = max(self.reward, self.eval(self.agent_state))\n",
        "    # Null reward everywhere except when the episode terminates\n",
        "    reward = self.reward if done else 0\n",
        "\n",
        "    # reward idea #2\n",
        "    # set the reward to that observed in the final state\n",
        "    #reward = self.eval(self.agent_state) if done else 0\n",
        "\n",
        "    # reward idea #3\n",
        "    # let the agent accumulate reward as it goes\n",
        "    # self.reward += self.eval(self.agent_state)\n",
        "    # reward = self.reward\n",
        "\n",
        "    if self.eval(self.agent_state) > self.best['val']:\n",
        "      self.best = {'state':copy.deepcopy(self.agent_state), 'val':self.eval(self.agent_state)}\n",
        "\n",
        "    # Optionally we can pass additional info\n",
        "    info = {}\n",
        "    info['best'] = self.best\n",
        "    info['visited'] = self.visited\n",
        "\n",
        "    return np.array(self.agent_state), reward, done, info\n",
        "\n",
        "  def render(self, mode='console'):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "    # agent is represented as a cross, rest as a dot\n",
        "    print(\".\" * self.agent_state, end=\"\")\n",
        "    print(\"x\", end=\"\")\n",
        "    print(\".\" * (self.grid_size - self.agent_state))\n",
        "\n",
        "  def close(self):\n",
        "    pass\n",
        "\n",
        "# check and make sure the environment is sane and working\n",
        "#from stable_baselines.common.env_checker import check_env\n",
        "\n",
        "# If the environment doesn't follow the interface, an error will be thrown\n",
        "# env = HypRLGridEnv()\n",
        "# check_env(env, warn=True)\n",
        "#env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnOq39NCtzbi"
      },
      "source": [
        "### RL Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_gxuc5NtwcW",
        "outputId": "be178825-fc21-40ab-a18d-10ae40dc1b37"
      },
      "source": [
        "from stable_baselines3 import DQN, PPO, A2C\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "#from stable_baselines3.common.policies import MlpPolicy\n",
        "import pdb\n",
        "# # Instantiate the env\n",
        "env = HypRLGridEnv()\n",
        "# wrap it\n",
        "env = make_vec_env(lambda: env, n_envs=1)\n",
        "\n",
        "# Train the agent\n",
        "##model = ACKTR('MlpPolicy', env, verbose=1).learn(5000)\n",
        "model = A2C('MlpPolicy', env, verbose=0)\n",
        "model.learn(total_timesteps=25000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running evaluation for : {'learning_rate': 1.0, 'batch_size': 2}\n",
            "Accuracy of the network on the 2500 test images: 10.04%\n",
            "Running evaluation for : {'learning_rate': 0.1, 'batch_size': 4}\n",
            "Accuracy of the network on the 1250 test images: 10.06%\n",
            "Running evaluation for : {'learning_rate': 0.01, 'batch_size': 4}\n",
            "Accuracy of the network on the 1250 test images: 24.78%\n",
            "Running evaluation for : {'learning_rate': 0.01, 'batch_size': 2}\n",
            "Accuracy of the network on the 2500 test images: 10.22%\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 2}\n",
            "Accuracy of the network on the 2500 test images: 46.92%\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 4}\n",
            "Accuracy of the network on the 1250 test images: 45.82%\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 6}\n",
            "Accuracy of the network on the 834 test images: 44.86%\n",
            "Running evaluation for : {'learning_rate': 0.0001, 'batch_size': 6}\n",
            "Accuracy of the network on the 834 test images: 12.5%\n",
            "Running evaluation for : {'learning_rate': 0.0001, 'batch_size': 8}\n",
            "Accuracy of the network on the 625 test images: 13.34%\n",
            "Running evaluation for : {'learning_rate': 0.01, 'batch_size': 6}\n",
            "Accuracy of the network on the 834 test images: 37.34%\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 8}\n",
            "Accuracy of the network on the 625 test images: 42.26%\n",
            "Running evaluation for : {'learning_rate': 0.0001, 'batch_size': 4}\n",
            "Accuracy of the network on the 1250 test images: 25.28%\n",
            "Running evaluation for : {'learning_rate': 0.01, 'batch_size': 8}\n",
            "Accuracy of the network on the 625 test images: 39.28%\n",
            "Running evaluation for : {'learning_rate': 0.0001, 'batch_size': 2}\n",
            "Accuracy of the network on the 2500 test images: 32.44%\n",
            "Running evaluation for : {'learning_rate': 1.0, 'batch_size': 8}\n",
            "Accuracy of the network on the 625 test images: 10.04%\n",
            "Running evaluation for : {'learning_rate': 0.1, 'batch_size': 8}\n",
            "Accuracy of the network on the 625 test images: 9.62%\n",
            "Running evaluation for : {'learning_rate': 1.0, 'batch_size': 6}\n",
            "Accuracy of the network on the 834 test images: 10.74%\n",
            "Running evaluation for : {'learning_rate': 1.0, 'batch_size': 4}\n",
            "Accuracy of the network on the 1250 test images: 10.04%\n",
            "Running evaluation for : {'learning_rate': 0.1, 'batch_size': 2}\n",
            "Accuracy of the network on the 2500 test images: 10.22%\n",
            "Running evaluation for : {'learning_rate': 0.1, 'batch_size': 6}\n",
            "Accuracy of the network on the 834 test images: 9.9%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x7fc365b71a50>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb0mvA28dKRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41131cca-ca5d-43e5-ab98-c0591a145233"
      },
      "source": [
        "# Test the trained agent for sanity checking on the same environment\n",
        "\n",
        "obs = env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  # print(\"Step {}\".format(step + 1))\n",
        "  # print(\"Action: \", action)\n",
        "  #pdb.set_trace()\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  if done:\n",
        "    # Note that the VecEnv resets automatically\n",
        "    # when a done signal is encountered\n",
        "    print(\"Goal reached!\", \"reward=\", reward, \"final_state=\", info[0]['terminal_observation'], \"best=\", info[0]['best'])\n",
        "    print(f\"info {info}\")\n",
        "    break\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done, 'info', info)\n",
        "  #env.render(mode='console')\n",
        "\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "print(f\"{env.envs[0].eval_cache}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs= [[1 0]] reward= [0.000] done= [False] info [{'best': {'state': array([1, 0]), 'val': 46.92}, 'visited': {(1, 1): True, (1, 0): True}}]\n",
            "Goal reached! reward= [46.920] final_state= [1 0] best= {'state': array([1, 0]), 'val': 46.92}\n",
            "info [{'best': {'state': array([1, 0]), 'val': 46.92}, 'visited': {(1, 1): True, (1, 0): True}, 'episode': {'r': 46.92, 'l': 2, 't': 1739.919808}, 'terminal_observation': array([1, 0])}]\n",
            "[[32.440 25.280 12.500 13.340]\n",
            " [46.920 45.820 44.860 42.260]\n",
            " [10.220 24.780 37.340 39.280]\n",
            " [10.220 10.060 9.900 9.620]\n",
            " [10.040 10.040 10.740 10.040]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oEd0rDpAYHI"
      },
      "source": [
        "## Time to perform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUKMx8hSuUTx"
      },
      "source": [
        "# Instantiate a full environment\n",
        "env_real = HypRLGridEnv(TunableHP(hyp_opt_trainset, hyp_opt_trainset))\n",
        "# wrap it\n",
        "env_real = make_vec_env(lambda: env_real, n_envs=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CsUbWSWDyPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f24b130-8e8e-49fb-cfea-26da47b04b81"
      },
      "source": [
        "# Test the trained agent on a new and full environment of the same dataset\n",
        "obs = env_real.reset()\n",
        "print('obs=', obs)\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  print(\"Action: \", action)\n",
        "  #pdb.set_trace()\n",
        "  obs, reward, done, info = env_real.step(action)\n",
        "  if done:\n",
        "    # Note that the VecEnv resets automatically\n",
        "    # when a done signal is encountered\n",
        "    print(\"Goal reached!\", \"reward=\", reward, \"final_state=\", info[0]['terminal_observation'])\n",
        "    break\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "print(env_real.envs[0].eval_cache)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running evaluation for : {'learning_rate': 0.1, 'batch_size': 4}\n",
            "obs= [[4 1]]\n",
            "Step 1\n",
            "Action:  [[1.000 1.000]]\n",
            "Running evaluation for : {'learning_rate': 1.0, 'batch_size': 9}\n",
            "obs= [[5 2]] reward= [9.400] done= [False]\n",
            "Step 2\n",
            "Action:  [[-1.000 1.000]]\n",
            "Running evaluation for : {'learning_rate': 0.1, 'batch_size': 6}\n",
            "obs= [[4 3]] reward= [10.000] done= [False]\n",
            "Step 3\n",
            "Action:  [[-1.000 1.000]]\n",
            "Running evaluation for : {'learning_rate': 0.01, 'batch_size': 8}\n",
            "obs= [[3 4]] reward= [10.080] done= [False]\n",
            "Step 4\n",
            "Action:  [[-1.000 1.000]]\n",
            "Running evaluation for : {'learning_rate': 2.0, 'batch_size': 8}\n",
            "obs= [[2 4]] reward= [26.080] done= [False]\n",
            "Step 5\n",
            "Action:  [[-1.000 -0.942]]\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 6}\n",
            "obs= [[1 3]] reward= [26.086] done= [False]\n",
            "Step 6\n",
            "Action:  [[1.000 -1.000]]\n",
            "Running evaluation for : {'learning_rate': 2.0, 'batch_size': 9}\n",
            "obs= [[2 2]] reward= [44.086] done= [False]\n",
            "Step 7\n",
            "Action:  [[-1.000 -0.920]]\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 4}\n",
            "obs= [[1 1]] reward= [44.090] done= [False]\n",
            "Step 8\n",
            "Action:  [[1.000 -0.608]]\n",
            "Running evaluation for : {'learning_rate': 2.0, 'batch_size': 2}\n",
            "obs= [[2 0]] reward= [48.090] done= [False]\n",
            "Step 9\n",
            "Action:  [[-1.000 -0.564]]\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 2}\n",
            "obs= [[1 0]] reward= [48.092] done= [False]\n",
            "Step 10\n",
            "Action:  [[1.000 -0.208]]\n",
            "Running evaluation for : {'learning_rate': 0.001, 'batch_size': 9}\n",
            "Goal reached! reward= [52.092] final_state= [2 0]\n",
            "[[0.000 0.000 0.000 0.000 0.000]\n",
            " [0.002 0.004 0.009 0.006 0.000]\n",
            " [4.000 0.000 18.000 0.000 16.000]\n",
            " [0.000 0.000 0.000 0.000 0.080]\n",
            " [0.000 0.400 0.000 0.600 0.000]\n",
            " [0.000 0.000 9.000 0.000 0.000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR8AqJ35cHtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12d1563-870e-4863-abf6-e2f05db0990d"
      },
      "source": [
        "print(env_real.envs[0].eval_cache)\n",
        "obs = env_real.reset()\n",
        "print('obs=', obs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.000 0.000 0.000 0.000 0.000]\n",
            " [0.002 0.004 0.009 0.006 0.000]\n",
            " [4.000 0.000 18.000 0.000 16.000]\n",
            " [0.000 0.000 0.000 0.000 0.080]\n",
            " [0.000 0.400 0.000 0.600 0.000]\n",
            " [0.000 0.000 9.000 0.000 0.000]]\n",
            "Running evaluation for : {'learning_rate': 1.0, 'batch_size': 8}\n",
            "obs= [[5 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEnq60GncQSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f156445-c281-40e9-f52f-8dcf10d06452"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "kfold.split(trainset)\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(trainset)):\n",
        "  print(f\"fold {fold} ... train {len(train_ids)} ... test {len(test_ids)}\")\n",
        "\n",
        "kfold.get_n_splits()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 ... train 45000 ... test 5000\n",
            "fold 1 ... train 45000 ... test 5000\n",
            "fold 2 ... train 45000 ... test 5000\n",
            "fold 3 ... train 45000 ... test 5000\n",
            "fold 4 ... train 45000 ... test 5000\n",
            "fold 5 ... train 45000 ... test 5000\n",
            "fold 6 ... train 45000 ... test 5000\n",
            "fold 7 ... train 45000 ... test 5000\n",
            "fold 8 ... train 45000 ... test 5000\n",
            "fold 9 ... train 45000 ... test 5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}